{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce the ablation study table, kmeans agreement score table and flow prediction performance boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tikzplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = [6.5, 4.4]\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['font.family'] = 'serif' \n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_type = 'multimodal'\n",
    "\n",
    "assert synthetic_type == 'unimodal' or synthetic_type == 'multimodal'\n",
    "\n",
    "figures_save_folder = f\"figures/ablation_{synthetic_type}/\"\n",
    "tables_save_folder = f\"tables/ablation_{synthetic_type}/\"\n",
    "os.makedirs(figures_save_folder, exist_ok=True)\n",
    "os.makedirs(tables_save_folder, exist_ok=True)\n",
    "\n",
    "# compare_inx = 5 if synthetic_type == 'unimodal' else 2\n",
    "\n",
    "model_dict = {\"dnn2_engi_feat\": 'f.e.+\\ndnn2', \n",
    "              \"dnn2_node2vec\": 'n2v+\\ndnn2',\n",
    "              \"dnn2_both\": 'both+\\ndnn2',\n",
    "              'gated': 'gated', \n",
    "              'grad': 'grad',\n",
    "              'fairness_goodness': \"Kumar\\net.al.\"}\n",
    "\n",
    "repr_dict = {\"dnn2_engi_feat\": 'engi. feat.', \n",
    "             \"dnn2_node2vec\": 'node2vec', \n",
    "             \"dnn2_both\": 'both',\n",
    "             'gated': 'gated', \n",
    "             'grad': 'grad'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(graph_name, synthetic_type):\n",
    "    RESULTS_TMPL = \"results/{}_{}/\"\n",
    "    BASELINE_TMPL = \"{}_ablation_baseline_results.csv\"\n",
    "    GRAD_TMPL = \"{}_ablation_grad_baseline_results.csv\"\n",
    "    GATED_GRAD_TMPL = \"{}_ablation_joint_results.csv\"\n",
    "    FAIRNESS_GOODNESS_TMPL = \"{}_ablation_fairness_goodness.csv\"\n",
    "    INIT_TMPL = \"{}_ablation_init_results.csv\"\n",
    "    FLOW_INFO_TMPL = \"flow_info.csv\"\n",
    "    folder = RESULTS_TMPL.format(graph_name, synthetic_type)\n",
    "    \n",
    "    results = dict()\n",
    "    \n",
    "    results[\"gated\"] = pd.read_csv(os.path.join(\n",
    "        folder, GATED_GRAD_TMPL.format(graph_name)\n",
    "    ))\n",
    "    \n",
    "    results[\"grad\"] = pd.read_csv(os.path.join(\n",
    "        folder, GRAD_TMPL.format(graph_name)\n",
    "    ))\n",
    "    \n",
    "    baseline_df = pd.read_csv(os.path.join(\n",
    "        folder, BASELINE_TMPL.format(graph_name)\n",
    "    ))\n",
    "    unique_baselines = baseline_df.baseline_name.unique()\n",
    "    for bl in unique_baselines:\n",
    "        results[bl] = baseline_df.loc[baseline_df.baseline_name == bl, :]\n",
    "    \n",
    "\n",
    "    \n",
    "    results[\"fairness_goodness\"] = pd.read_csv(os.path.join(\n",
    "        folder, FAIRNESS_GOODNESS_TMPL.format(graph_name)\n",
    "    ))\n",
    "\n",
    "\n",
    "    results[\"init\"] = pd.read_csv(os.path.join(\n",
    "        folder, INIT_TMPL.format(graph_name)\n",
    "    ))\n",
    "    \n",
    "\n",
    "    results[\"flow_info\"] = pd.read_csv(os.path.join(\n",
    "        folder, FLOW_INFO_TMPL\n",
    "    ))\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_models_repr_columns(results):\n",
    "    for graph_name, results_ in results.items():\n",
    "        for key, df in results_.items():\n",
    "            df['models'] = model_dict.get(key, key)\n",
    "            df['representations'] = repr_dict.get(key, key)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_abl_inx(results, column=\"val_median_mag_error\", select=\"min\"):\n",
    "    abl_inx_dict = dict()\n",
    "    for graph_name, results_ in results.items():\n",
    "        abl_inx_dict[graph_name] = dict()\n",
    "        for key, df in results_.items():\n",
    "            if \"ablation_idx\" not in df.columns:\n",
    "                continue\n",
    "            grouped = df.groupby(\"ablation_idx\").agg({column: \"mean\"})\n",
    "            abl_idx = grouped.idxmin().item()\n",
    "            abl_inx_dict[graph_name][key] = abl_idx\n",
    "    return abl_inx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_names = [\"complete\", \"cora\", \"bitcoin\"]\n",
    "selected_models = [ 'gated', 'grad', \"dnn2_engi_feat\", \"dnn2_node2vec\", \"fairness_goodness\"]\n",
    "results = dict()\n",
    "for graph_name in graph_names:\n",
    "    results[graph_name] = load_results(graph_name, synthetic_type)\n",
    "results = add_models_repr_columns(results)\n",
    "abl_inx_dict = get_best_abl_inx(results)\n",
    "\n",
    "best_results = dict()\n",
    "for graph_name in graph_names:\n",
    "    best_results[graph_name] = []\n",
    "    for key, result in results[graph_name].items():\n",
    "        if key not in selected_models:\n",
    "            continue\n",
    "        best_results[graph_name].append(result.loc[(result['ablation_idx'] == abl_inx_dict[graph_name][key]), :])\n",
    "    best_results[graph_name] = pd.concat(best_results[graph_name], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create ablation study table\n",
    "def make_init_improvement_table(grad_results, col='median_mag_error', new_name='error*'):\n",
    "    \n",
    "    columns = [f'train_{col}', f'val_{col}']\n",
    "    names = [f'train {new_name}', f'val {new_name}']\n",
    "    name_mapper = dict(zip(columns, names))\n",
    "    name_mapper['ablation_idx'] = 'init and reg.'\n",
    "    \n",
    "    \n",
    "\n",
    "    df_results = grad_results.loc[:, [f'train_{col}', f'val_{col}', 'ablation_idx']]\n",
    "    df_results['ablation_idx'] = df_results['ablation_idx'].map({0: 'normal noise', \n",
    "                                                                 1: 'LSQR', \n",
    "                                                                 2: 'LSQR+',\n",
    "                                                                 3: 'LSQR+, L1($u$)',\n",
    "                                                                 4: 'LSQR+, L1($z$)',\n",
    "                                                                 5: 'LSQR+, L1($u$), L1($z$)'\n",
    "                                                                })\n",
    "    \n",
    "    \n",
    "    all_res_df = df_results.rename(name_mapper, axis='columns')\n",
    "    \n",
    "    out = all_res_df.groupby(['init and reg.'], sort=False).agg({\n",
    "        f'val {new_name}': ['mean', 'std'],\n",
    "        f'train {new_name}': ['mean', 'std']})\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create train and validation box plot\n",
    "def make_comparison(best_results, score='median_mag_error', split=\"val\"):\n",
    "    \n",
    "    res = best_results.loc[:, ['models']]\n",
    "    res[score] = best_results[f'{split}_{score}']\n",
    "    \n",
    "#     res['models'] = ['models'].map\n",
    "    \n",
    "    return res\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmeans_agreement_score_comparison(best_results, score='multimodal_score'):\n",
    "    res_val = best_results.loc[:, ['representations']]\n",
    "    res_val[score] = best_results[score]\n",
    "    res_val = res_val.rename({'multimodal_score': 'k-means agreement'}, axis='columns')\n",
    "    out = res_val.groupby('representations', sort=False).agg({'k-means agreement': ['mean', 'std']})\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To a dense comparison of training and validation results for all models\n",
    "def setup_df_for_ablation_plot_all_train_val(results_dict, score='loss', remove_index=False):\n",
    "    for key, result in results_dict.items():\n",
    "        if key == 'baseline' or key == 'baselines':\n",
    "            result['models'] = result['baseline_name']\n",
    "        else:\n",
    "            result['models'] = key\n",
    "    all_res = pd.concat(list(results_dict.values()))\n",
    "\n",
    "    res_val = all_res.loc[:, ['models', 'ablation_idx']]\n",
    "    res_val[score] = all_res[f'val_{score}']\n",
    "    res_val['split'] = 'val'\n",
    "\n",
    "    res_train = all_res.loc[:, ['models', 'ablation_idx']]\n",
    "    res_train[score] = all_res[f'train_{score}']\n",
    "    res_train['split'] = 'train'\n",
    "\n",
    "    split_res = pd.concat((res_train, res_val))\n",
    "    if remove_index:\n",
    "        split_res = remove_abl_inx(split_res, remove_index)\n",
    "    return split_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_improvement(results, graph_name):\n",
    "    gated_init_improvment = make_init_improvement_table(results[\"gated\"])\n",
    "    gated_init_improvment.to_latex(os.path.join(tables_save_folder, f\"{graph_name}_init_improvement.tex\"), \n",
    "                                        escape=False, float_format=\"%.2f\")\n",
    "    print(gated_init_improvment)\n",
    "\n",
    "def agreement_score(results, graph_name):\n",
    "    if synthetic_type != 'multimodal':\n",
    "        print(\"agreement score only for mulimodal\")\n",
    "        return\n",
    "    out = make_kmeans_agreement_score_comparison(results)\n",
    "    out.to_latex(os.path.join(tables_save_folder, f\"{graph_name}_kmeans_agreement.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)\n",
    "    \n",
    "def plot_boxes(results, graph_name, split):\n",
    "#     score = 'median_mag_error'\n",
    "#     score_name=r'log$_{10}$ median rel. error'\n",
    "    score = 'MeAE'\n",
    "    score_name='median abs. error'\n",
    "    data = make_comparison(results, score=score, split=split)\n",
    "    g = sns.catplot(x=\"models\", y=score,\n",
    "                    data=data, \n",
    "                    kind='box', \n",
    "                    linewidth=1.5)\n",
    "    g.set(ylabel=score_name)\n",
    "    sns.despine(left=True)\n",
    "    xticklabels = list(x._text for x in g_val._axes[0][0].get_xticklabels())\n",
    "    xticklabels_latex =  list(x.replace(\"\\n\", \"\\\\\\\\\") for x in xticklabels)\n",
    "    g.set_xticklabels(xticklabels_latex)\n",
    "    tikzplotlib.save(os.path.join(figures_save_folder, f\"{graph_name}_{split}_{score}.tex\"),\n",
    "                    extra_axis_parameters=[\"xticklabel style={align=center}\"])\n",
    "    g.set_xticklabels(xticklabels)\n",
    "    g.fig.savefig(os.path.join(figures_save_folder, f\"{graph_name}_{split}_{score}.pdf\"), bbox_inches='tight')\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        val error*           train error*          \n",
      "                              mean       std         mean       std\n",
      "init and reg.                                                      \n",
      "normal noise             -0.241383  0.476888    -0.362094  0.467781\n",
      "LSQR                     -1.932587  0.150376    -1.978806  0.141921\n",
      "LSQR+                    -2.145107  0.119173    -2.231552  0.076645\n",
      "LSQR+, L1($u$)           -2.219471  0.176254    -2.303269  0.140972\n",
      "LSQR+, L1($z$)           -1.337606  0.100248    -1.421767  0.044577\n",
      "LSQR+, L1($u$), L1($z$)  -1.435877  0.092178    -1.477079  0.055322\n",
      "                  k-means agreement          \n",
      "                               mean       std\n",
      "representations                              \n",
      "gated                        0.9525  0.102368\n",
      "grad                         0.5725  0.046323\n",
      "engi. feat.                  1.0000  0.000000\n",
      "node2vec                     0.4075  0.037361\n",
      "fairness_goodness               NaN       NaN\n",
      "                        val error*           train error*          \n",
      "                              mean       std         mean       std\n",
      "init and reg.                                                      \n",
      "normal noise             -0.008808  0.000257    -0.297259  0.014974\n",
      "LSQR                     -1.317453  0.023911    -1.952797  0.013082\n",
      "LSQR+                    -1.195934  0.027758    -2.075697  0.016836\n",
      "LSQR+, L1($u$)           -1.061182  0.029204    -2.032710  0.010766\n",
      "LSQR+, L1($z$)           -0.878792  0.017886    -1.393024  0.005707\n",
      "LSQR+, L1($u$), L1($z$)  -0.910253  0.016697    -1.412151  0.008420\n",
      "                  k-means agreement          \n",
      "                               mean       std\n",
      "representations                              \n",
      "gated                      0.924373  0.002297\n",
      "grad                       0.689725  0.001476\n",
      "engi. feat.                0.679880  0.003447\n",
      "node2vec                   0.338450  0.002418\n",
      "fairness_goodness               NaN       NaN\n",
      "                        val error*           train error*          \n",
      "                              mean       std         mean       std\n",
      "init and reg.                                                      \n",
      "normal noise             -0.008742  0.002650    -0.360663  0.159621\n",
      "LSQR                     -0.779351  0.079379    -2.265493  0.064517\n",
      "LSQR+                    -0.807002  0.058802    -2.391968  0.067142\n",
      "LSQR+, L1($u$)           -0.672968  0.091695    -2.216319  0.041270\n",
      "LSQR+, L1($z$)           -0.556315  0.070665    -1.399117  0.020245\n",
      "LSQR+, L1($u$), L1($z$)  -0.622053  0.068661    -1.393353  0.034632\n",
      "                  k-means agreement          \n",
      "                               mean       std\n",
      "representations                              \n",
      "gated                      0.895955  0.028492\n",
      "grad                       0.709504  0.043265\n",
      "engi. feat.                0.618188  0.013622\n",
      "node2vec                   0.338555  0.001304\n",
      "fairness_goodness               NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "for graph_name in graph_names:\n",
    "    init_improvement(results[graph_name], graph_name)\n",
    "    agreement_score(best_results[graph_name], graph_name)\n",
    "#     g_val = plot_boxes(best_results[graph_name], graph_name, \"val\")\n",
    "#     g_val = plot_boxes(best_results[graph_name], graph_name, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_joint_init_improvment = make_init_improvement_table(complete_joint_results)\n",
    "complete_joint_init_improvment.to_latex(os.path.join(tables_save_folder, \"complete_init_improvement.tex\"), \n",
    "                                        escape=False, float_format=\"%.2f\")\n",
    "complete_joint_init_improvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthetic_type == 'traders':\n",
    "    out = make_kmeans_agreement_score_comparison(complete_result_dict)\n",
    "    out.to_latex(os.path.join(tables_save_folder, \"complete_kmeans_agreement.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)\n",
    "    out = make_kmeans_agreement_score_comparison_std(complete_result_dict)\n",
    "    out.to_latex(os.path.join(tables_save_folder, \"complete_kmeans_agreement_std.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "score_name=r'log$_{10}$ median rel. error'\n",
    "complete_comp_data = make_val_comparison(complete_result_dict, score=score)\n",
    "g = sns.catplot(x=\"models\", y=score,\n",
    "                data=complete_comp_data, \n",
    "                kind='box', \n",
    "                linewidth=1.5)\n",
    "g.set(ylabel=score_name)\n",
    "sns.despine(left=True)\n",
    "tikzplotlib.save(os.path.join(figures_save_folder, \"complete_val_median_mag_error.tex\"))\n",
    "g.fig.savefig(os.path.join(figures_save_folder, \"complete_val_median_mag_error.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "score_name=r'log$_{10}$ median rel. error'\n",
    "complete_comp_data = make_train_comparison(complete_result_dict, score=score)\n",
    "g = sns.catplot(x=\"models\", y=score,\n",
    "                data=complete_comp_data, \n",
    "                kind='box', \n",
    "                linewidth=1.5)\n",
    "g.set(ylabel=score_name)\n",
    "sns.despine(left=True)\n",
    "tikzplotlib.save(os.path.join(figures_save_folder, \"complete_train_median_mag_error.tex\"))\n",
    "g.fig.savefig(os.path.join(figures_save_folder, \"complete_train_median_mag_error.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "violin_res = setup_df_for_ablation_plot_all_train_val(complete_result_dict, \n",
    "                                                 score=score, remove_index=False)\n",
    "g = sns.catplot(x=\"ablation_idx\", y=score, \n",
    "                hue=\"models\", col='split',\n",
    "                data=violin_res, \n",
    "                kind='box',\n",
    "                height=5, aspect=1., linewidth=1.)\n",
    "sns.despine(left=True)\n",
    "# g.fig.savefig(os.path.join(save_folder, \"complete_loss.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_joint_init_improvment = make_init_improvement_table(cora_joint_results)\n",
    "cora_joint_init_improvment.to_latex(os.path.join(tables_save_folder, \"cora_init_improvement.tex\"), \n",
    "                                    escape=False, float_format=\"%.2f\")\n",
    "cora_joint_init_improvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthetic_type == 'traders':\n",
    "    out = make_kmeans_agreement_score_comparison(cora_result_dict)\n",
    "    out.to_latex(os.path.join(tables_save_folder, \"cora_kmeans_agreement.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)\n",
    "    out = make_kmeans_agreement_score_comparison_std(cora_result_dict)\n",
    "    out.to_latex(os.path.join(tables_save_folder, \"cora_kmeans_agreement_std.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "score_name='$\\log_{10}$ median rel. error'\n",
    "cora_comp_data = make_val_comparison(cora_result_dict, score=score)\n",
    "g = sns.catplot(x=\"models\", y=score, \n",
    "                data=cora_comp_data, \n",
    "                kind='box',\n",
    "                aspect=1., \n",
    "                linewidth=1.5)\n",
    "g.set(ylabel=score_name)\n",
    "sns.despine(left=True)\n",
    "tikzplotlib.save(os.path.join(figures_save_folder, \"cora_val_median_mag_error.tex\"))\n",
    "g.fig.savefig(os.path.join(figures_save_folder, \"cora_val_median_mag_error.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "score_name='$\\log_{10}$ median rel. error'\n",
    "cora_comp_data = make_train_comparison(cora_result_dict, score=score)\n",
    "g = sns.catplot(x=\"models\", y=score, \n",
    "                data=cora_comp_data, \n",
    "                kind='box',\n",
    "                aspect=1., \n",
    "                linewidth=1.5)\n",
    "g.set(ylabel=score_name)\n",
    "sns.despine(left=True)\n",
    "tikzplotlib.save(os.path.join(figures_save_folder, \"cora_train_median_mag_error.tex\"))\n",
    "g.fig.savefig(os.path.join(figures_save_folder, \"cora_train_median_mag_error.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "violin_res = setup_df_for_ablation_plot_all_train_val(cora_result_dict, \n",
    "                                                 score=score, remove_index=False)\n",
    "g = sns.catplot(x=\"ablation_idx\", y=score, \n",
    "                hue=\"models\", col='split',\n",
    "                data=violin_res, \n",
    "                kind='box',\n",
    "                height=5, aspect=1., linewidth=1.)\n",
    "sns.despine(left=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_joint_init_improvment = make_init_improvement_table(bitcoin_joint_results)\n",
    "bitcoin_joint_init_improvment.to_latex(os.path.join(tables_save_folder, \"bitcoin_init_improvement.tex\"), \n",
    "                                       escape=False, float_format=\"%.2f\")\n",
    "bitcoin_joint_init_improvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthetic_type == 'traders':\n",
    "    out = make_kmeans_agreement_score_comparison(bitcoin_result_dict)\n",
    "    out.to_latex(os.path.join(tables_save_folder, \"bitcoin_kmeans_agreement.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)\n",
    "    out = make_kmeans_agreement_score_comparison_std(bitcoin_result_dict)\n",
    "    out.to_latex(os.path.join(tables_save_folder, \"bitcoin_kmeans_agreement_std.tex\"), escape=False, float_format=\"%.2f\")\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "score_name='$\\log_{10}$ median rel. error'\n",
    "bitcoin_comp_data = make_val_comparison(bitcoin_result_dict, score=score)\n",
    "g = sns.catplot(x=\"models\", y=score, \n",
    "                data=bitcoin_comp_data, \n",
    "                kind='box',\n",
    "                aspect=1., \n",
    "                linewidth=1.5)\n",
    "g.set(ylabel=score_name)\n",
    "sns.despine(left=True)\n",
    "tikzplotlib.save(os.path.join(figures_save_folder, \"bitcoin_val_median_mag_error.tex\"))\n",
    "g.fig.savefig(os.path.join(figures_save_folder, \"bitcoin_val_median_mag_error.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "score_name='$\\log_{10}$ median rel. error'\n",
    "bitcoin_comp_data = make_train_comparison(bitcoin_result_dict, score=score)\n",
    "g = sns.catplot(x=\"models\", y=score, \n",
    "                data=bitcoin_comp_data, \n",
    "                kind='box',\n",
    "                aspect=1., \n",
    "                linewidth=1.5)\n",
    "g.set(ylabel=score_name)\n",
    "sns.despine(left=True)\n",
    "tikzplotlib.save(os.path.join(figures_save_folder, \"bitcoin_train_median_mag_error.tex\"))\n",
    "g.fig.savefig(os.path.join(figures_save_folder, \"bitcoin_train_median_mag_error.pdf\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'median_mag_error'\n",
    "violin_res = setup_df_for_ablation_plot_all_train_val(bitcoin_result_dict, \n",
    "                                                 score=score, remove_index=False)\n",
    "g = sns.catplot(x=\"ablation_idx\", y=score, \n",
    "                hue=\"models\", col='split',\n",
    "                data=violin_res, \n",
    "                kind='box',\n",
    "                height=5, aspect=1., linewidth=1.)\n",
    "g.set(ylim=(-2.5, 0.1))\n",
    "sns.despine(left=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
